{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adquisición de datos en Python - PRA02\n",
    "--------------------------------------\n",
    "\n",
    "\n",
    "En este Notebook encontraréis dos conjuntos de ejercicios: un primer conjunto de **ejercicios para practicar** y un segundo conjunto de **actividades evaluables** como PRÁCTICAS de la asignatura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos visto el uso de la libería [Requests](http://docs.python-requests.org/) para realizar peticiones a web API de manera manual.\n",
    "\n",
    "Mediante esta librería podemos realizar solicitudes como en el ejemplo que hemos visto de [postcodes.io](http://postcodes.io).\n",
    "\n",
    "`response = requests.get('http://api.postcodes.io/postcodes/E98%201TT')`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Hemos visto que, en realizar una petición a una web API http, recuperamos un objeto que contiene, entre otros, los siguientes atributos: **status.code**, **content** y **headers**. Busca la información sobre los códigos de **status.code** y completa la siguiente tabla sobre los códigos de error http. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**\n",
    "\n",
    "Descripción de los principales códigos de error http:\n",
    "\n",
    "- **200: \"OK\"**; significa que la solicitud ha tenido éxito, el significado de un éxito varía dependiendo del método HTTP.\n",
    "- **301: \"Moved Permanently\"**; este código de respuesta significa que la URI  del recurso solicitado ha sido cambiado, probablemente una nueva URI sea devuelta en la respuesta.\n",
    "- **400: \"Bad Request\"**; esta respuesta significa que el servidor no pudo interpretar la solicitud dada una sintaxis inválida.\n",
    "- **401: \"Unauthorized\"**; esta respuesta significa que es necesario autenticar para obtener la respuesta solicitada. Esta respuesta es similar a la 403, pero en este caso, la autenticación es posible.\n",
    "- **403: \"Forbidden\"**; significa que el cliente no posee los permisos necesarios para acceder a cierto contenido, por lo que el servidor está rechazando otorgar una respuesta apropiada.\n",
    "- **404: \"Not Found\"**; esta respuesta significa que el servidor no pudo encontrar el contenido solicitado. Este código de respuesta es uno de los más famosos dada su alta ocurrencia en la web.\n",
    "- **501: \"Not Implemented\"**; significa que el método solicitado no está soportado por el servidor y no puede ser manejado. Los únicos métodos que los servidores requieren soporte (y por lo tanto no deben retornar este código) son `GET` y `HEAD`.\n",
    "- **505: \"HTTP Version Not Supported\"**; esta respuesta significa que la versión de HTTP usada en la petición no está soportada por el servidor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio intentaremos hacer una solicitud a tres paginas web diferentes vía el protocolo http mediante el método GET implementado en `requests.get`.\n",
    "\n",
    "Obtén mediante `requests.get`, el contenido y el correspondiente `status.code` de las siguentes pàginas web: \n",
    "\n",
    "- http://google.com\n",
    "- http://wikipedia.org\n",
    "- https://mikemai.net/\n",
    "- http://google.com/noexisto\n",
    "\n",
    "Para cada web, muestra:\n",
    "\n",
    "- Los primeros 80 carácteres del contenido de la web \n",
    "- El código de `status.code`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El status code de la url http://google.com es: \n",
      " 200\n",
      "El contenido de la url http://google.com es: \n",
      " <!doctype html><html itemscope=\"\" itemtype=\"http://schema.org/WebPage\" lang=\"es\"\n",
      "El status code de la url http://wikipedia.org es: \n",
      " 200\n",
      "El contenido de la url http://wikipedia.org es: \n",
      " <!DOCTYPE html>\n",
      "<html lang=\"mul\" class=\"no-js\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\">\n",
      "<t\n",
      "El status code de la url https://mikemai.net/ es: \n",
      " 406\n",
      "El contenido de la url https://mikemai.net/ es: \n",
      " <head><title>Not Acceptable!</title><script src=\"/cdn-cgi/apps/head/Z5kPjcSfsgqj\n",
      "El status code de la url http://google.com/noexisto es: \n",
      " 404\n",
      "El contenido de la url http://google.com/noexisto es: \n",
      " <!DOCTYPE html>\n",
      "<html lang=en>\n",
      "  <meta charset=utf-8>\n",
      "  <meta name=viewport cont\n"
     ]
    }
   ],
   "source": [
    "# Importamos la librería requests.\n",
    "import requests\n",
    "\n",
    "# Guardamos las urls de las webs en una lista.\n",
    "urls = ['http://google.com', 'http://wikipedia.org', 'https://mikemai.net/', 'http://google.com/noexisto']\n",
    "\n",
    "# Iteramos y hacemos la llamadas, pintando por pantalla los datos solicitados.\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    print(f\"El status code de la url {url} es: \\n {response.status_code}\")\n",
    "    print(f\"El contenido de la url {url} es: \\n {response.text[0:80]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "\n",
    "En este ejercicio vamos a hacer un poco de *Fun with cats*. Existe una API para *cat-facts* (hechos sobre gatos) en la base de https://cat-fact.herokuapp.com. Esta API tiene dos puntos de acceso:\n",
    "\n",
    "- **/facts**\n",
    "- **/users**\n",
    "\n",
    "Según la documentación, el modelo en el punto de entrada de un **fact** es tal y como se indica a continuación: \n",
    "\n",
    "|    Key    |      Type     |                                              Description                                              |   |   |\n",
    "|:---------:|:-------------:|:-----------------------------------------------------------------------------------------------------:|---|---|\n",
    "| _id       | ObjectId      | Unique ID for the Fact                                                                                |   |   |\n",
    "| _v        | Number        | Version number of the Fact                                                                            |   |   |\n",
    "| user      | ObjectId      | ID of the User who added the Fact                                                                     |   |   |\n",
    "| text      | String        | The Fact itself                                                                                       |   |   |\n",
    "| updatedAt | Timestamp     | Date in which Fact was last modified                                                                  |   |   |\n",
    "| sendDate  | Timestamp     | If the Fact is meant for one time use, this is the date that it is used                               |   |   |\n",
    "| deleted   | Boolean       | Whether or not the Fact has been deleted (Soft deletes are used)                                      |   |   |\n",
    "| source    | String (enum) | Can be 'user' or 'api', indicates who added the fact to the DB                                        |   |   |\n",
    "| used      | Boolean       | Whether or not the Fact has been sent by the CatBot. This value is reset each time every Fact is used |   |   |\n",
    "| type      | String        | Type of animal the Fact describes (e.g. ‘cat’, ‘dog’, ‘horse’)                                        |   |   |\n",
    "\n",
    "Así, para obtener el **fact** número *58e0086f0aac31001185ed02*, debemos construir una solicitud a la url:\n",
    "\n",
    "- *https://cat-fact.herokuapp.com/facts/58e0086f0aac31001185ed02*\n",
    "\n",
    "El objecto que se nos devolverá, contendrá la información indicada en la tabla en formato *json* serializado. \n",
    "\n",
    "a) Contruye la solicitud, convierte el resultado a un diccionario y muestra por pantalla el resultado de los valores de la tabla anterior para el fact id *58e0086f0aac31001185ed02*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la librería json.\n",
    "import json\n",
    "\n",
    "# Creamos una función que solicita a la API un cat-fact concreto.\n",
    "def get_cat_fact(fact_id):\n",
    "    # Realizamos una petición GET a la API cat-facts.\n",
    "    response = requests.get(f'https://cat-fact.herokuapp.com/facts/{fact_id}')\n",
    "    # Deserializamos el objeto json.\n",
    "    dict_response = json.loads(response.text)\n",
    "    \n",
    "    return dict_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': {'verified': True, 'sentCount': 1},\n",
       " 'type': 'cat',\n",
       " 'deleted': False,\n",
       " '_id': '58e0086f0aac31001185ed02',\n",
       " 'user': {'name': {'first': 'Kasimir', 'last': 'Schulz'},\n",
       "  'photo': 'https://lh6.googleusercontent.com/-BS_rskGd3kA/AAAAAAAAAAI/AAAAAAAAADg/yAxrX9QabMg/photo.jpg?sz=200',\n",
       "  '_id': '58e007480aac31001185ecef'},\n",
       " 'text': \"Cats can't taste sweetness.\",\n",
       " '__v': 0,\n",
       " 'source': 'https://www.scientificamerican.com/article/strange-but-true-cats-cannot-taste-sweets/',\n",
       " 'updatedAt': '2020-08-29T20:20:03.172Z',\n",
       " 'createdAt': '2018-03-16T20:20:03.622Z',\n",
       " 'used': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos la función con el id proporcionado anteriormente.\n",
    "get_cat_fact(\"58e0086f0aac31001185ed02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Para los fact ids:\n",
    "\n",
    "- *5d38bdab0f1c57001592f156*\n",
    "- *5ed11e643c15f700172e3856*\n",
    "- *5ef556dff61f300017030d4c*\n",
    "- *5d9d4ae168a764001553b388*\n",
    "\n",
    "Obtén campos *type*, *user*, *user*, *source*, *used*, *text* y imprímelos siguiendo el siguiente formato:\n",
    "\n",
    "\n",
    "`Type: cat\tUser: 58e007480aac31001185ecef\n",
    "Used: True\tId: 58e0086f0aac31001185ed02\n",
    "Source: https://www.scientificamerican.com/article/strange-but-true-cats-cannot-taste-sweets/\n",
    "Text: Cats can't taste sweetness.`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: cat \t User: 5a9ac18c7478810ea6c06381\n",
      "Used: False \t Id: 5d38bdab0f1c57001592f156\n",
      "Source: user\n",
      "Text: While some cats love being brushed, others don't take to it naturally. Try to groom your cat in the same spot at the same time of day to create a sense of routine.\n",
      "----------------------------------------------------------------------------\n",
      "Type: cat \t User: 5ed11e353c15f700172e3855\n",
      "Used: False \t Id: 5ed11e643c15f700172e3856\n",
      "Source: user\n",
      "Text: Los gatos tienen más huesos que los seres humanos, nos ganan por 24.\n",
      "----------------------------------------------------------------------------\n",
      "Type: cat \t User: 5e1a9b981fd6150015fa736f\n",
      "Used: False \t Id: 5ef556dff61f300017030d4c\n",
      "Source: user\n",
      "Text: Lucy, the oldest cat ever, lived to be 39 years old which is equivalent to 172 cat years.\n",
      "----------------------------------------------------------------------------\n",
      "Type: cat \t User: 5d9d4a4468a764001553b387\n",
      "Used: False \t Id: 5d9d4ae168a764001553b388\n",
      "Source: user\n",
      "Text: Cats conserve energy by sleeping for an average of 13 to 14 hours a day.\n",
      "----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Guardamos los ids de los facts en una lista.\n",
    "ids = [\"5d38bdab0f1c57001592f156\", \"5ed11e643c15f700172e3856\", \"5ef556dff61f300017030d4c\", \"5d9d4ae168a764001553b388\"]\n",
    "\n",
    "# Iteramos y hacemos la llamadas, pintando por pantalla los datos solicitados.\n",
    "for fact_id in ids:\n",
    "    fact = get_cat_fact(fact_id)\n",
    "    print(f\"Type: {fact['type']} \\t User: {fact['user']['_id']}\")\n",
    "    print(f\"Used: {fact['used']} \\t Id: {fact['_id']}\")\n",
    "    print(f\"Source: {fact['source']}\")\n",
    "    print(f\"Text: {fact['text']}\")\n",
    "    print(f\"----------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "En los ejercicios anteriores, usamos directamente una API para hacer la solicitud que requiramos, y nos encargamos directamente de la gestión de los datos de salida. \n",
    "\n",
    "No obstante, hemos visto ya el uso de librerías que facilitan el accesso a una API. La mayoría de estas librerías (y APIs de proyectos populares) requieren de un registro en la web de desarolladores. \n",
    "\n",
    "\n",
    "Sigue la documentación proporcionada en clase para conseguir un registro en el panel de desarolladores de Twitter. Obtendrás 4 códigos para autenticar tu aplicación. \n",
    "\n",
    "Usa la librería **tweepy** para programar dos funciones. \n",
    "\n",
    "- La primera función, se autentica en la API de twitter usando los 4 códigos proporcionados por el registro. A partir de un nombre de usuario en twitter proporcionado en el argumento de la función, esta retorna una tupla `(user, api)` con el objeto `twepy.models.User`, correspondiente a ese usuario y el descriptor de la API ya inicializada. \n",
    "- La segunda funcion, aceptará un objeto  `twepy.models.User` de entrada y imprimirá: \n",
    " 1. El número de tweets del usuario.\n",
    " 1. El número de amigos del usuario.\n",
    " 1. El número de seguidores del usuario.\n",
    " 1. Los nombres de pantalla de los primeros 10 amigos del usuario (`screen_name`), sus nombres (`name`) junto con sus descripciones.\n",
    "\n",
    "Ejecuta las dos funciones sobre el usuario de twitter **Space_Station**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la librería tweepy.\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una función para la recogida de los credenciales.\n",
    "def get_creds(line):\n",
    "    keys = []\n",
    "    for l in line:\n",
    "        keys.append(l.split(\"=\")[1].splitlines(False)[0])\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un iterador para leer el fichero.\n",
    "tw_creeds = open(\"creds.txt\", \"r\")\n",
    "lines = tw_creeds.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procederemos con los creds de Twitter.\n",
    "CONSUMER_KEY = get_creds(lines)[0]\n",
    "CONSUMER_SECRET = get_creds(lines)[1]\n",
    "ACCESS_TOKEN = get_creds(lines)[2]\n",
    "ACCESS_TOKEN_SECRET = get_creds(lines)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la primera función que inicializa la API de Twitter y obtiene la información de un usuario.\n",
    "def init_twitter(user_name):\n",
    "    # Nos autenticamos con la API de Twitter.\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "    # Lanzamos la API.\n",
    "    api = tweepy.API(auth)\n",
    "    # Obtenemos datos del usuario elegido usando la librería tweepy.\n",
    "    user = api.get_user(user_name)\n",
    "    \n",
    "    return (user, api)\n",
    "    \n",
    "    \n",
    "# Creamos la segunda función que muestra por pantalla información del usuario.\n",
    "def print_info_twitter(user):\n",
    "    print(f\"El número de tweets del usuario es {user.statuses_count}\")\n",
    "    print(f\"El número de amigos del usuario es {user.friends_count}\")\n",
    "    print(f\"El número de seguidores del usuario es {user.followers_count}\")\n",
    "    print(f\"Los primeros diez amigos del usuario son: \")\n",
    "    for friend in user.friends()[0:10]:\n",
    "        print(f\"{friend.name} (@{friend.screen_name}): {friend.description}\")\n",
    "        print(\"---------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de tweets del usuario es 13732\n",
      "El número de amigos del usuario es 219\n",
      "El número de seguidores del usuario es 4179453\n",
      "Los primeros diez amigos del usuario son: \n",
      "Zebulon Scoville (@Explorer_Flight): 86th NASA Flight Director. Lucky husband and father. Always looking for a challenge. Tweets are my own, so don't blame NASA.\n",
      "---------------------------------------------------------------------\n",
      "Stephanie Wilson (@Astro_Stephanie): \n",
      "---------------------------------------------------------------------\n",
      "Jim Morhard (@jmorhard): Serving as @NASA's Deputy Administrator, working to support the agency's many missions including space exploration, Earth sciences, and aeronautics.\n",
      "---------------------------------------------------------------------\n",
      "Bob Cabana (@Astro_CabanaBob): Former astronaut and current Center Director of Kennedy Space Center.\n",
      "---------------------------------------------------------------------\n",
      "Sergey Kud-Sverchkov (@KudSverchkov): Космонавт Роскосмоса (@Roscosmos) Сергей Кудь-Сверчков\n",
      "//\n",
      "@Roscosmos cosmonaut Sergey Kud-Sverchkov\n",
      "---------------------------------------------------------------------\n",
      "U.S. Space Command (@US_SpaceCom): The OFFICIAL Twitter Page of United States Space Command, the 11th Combatant Command in the Department of Defense. #USSPACECOM\n",
      "---------------------------------------------------------------------\n",
      "Joshua Kutryk (@Astro_Kutryk): Canadian Space Agency Astronaut and RCAF Test Pilot.\n",
      "---------------------------------------------------------------------\n",
      "Ivan Vagner (@ivan_mks63): Космонавт Роскосмоса (@Roscosmos) Иван Вагнер\n",
      "//\n",
      "@Roscosmos cosmonaut Ivan Vagner\n",
      "---------------------------------------------------------------------\n",
      "Megan McArthur (@Astro_Megan): NASA Astronaut and veteran of Space Shuttle mission STS-125.\n",
      "---------------------------------------------------------------------\n",
      "Jasmin Moghbeli (@AstroJaws): Marine Attack Helicopter Pilot. Test Pilot. NASA Astronaut. Auntie to some ridiculously cool kids. Excited to share my journey!\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Probamos nuestras funciones, comenzando inicializando la API de Twitter y guardando el objeto creado en una variable.\n",
    "(user, api) = init_twitter(\"Space_Station\")\n",
    "\n",
    "# Llamamos a la segunda función y mostramos por pantalla la información que nos interesa de ese usuario.\n",
    "print_info_twitter(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 5\n",
    "\n",
    "[congreso.es](http://www.congreso.es/) es la página web del Congreso de los Diputados en España. En ella se guarda una relación de todos los diputados elegidos en cada una de las legislaturas. \n",
    "\n",
    "En una de las páginas se puede observar un mapa del hemiciclo, junto con la posición de cada uno de los diputados, su fotografía, su representación territorial y el partido político al que esté adscrito.  Esta url se encuentra en [Hemiciclo](http://www.congreso.es/portal/page/portal/Congreso/Congreso/Diputados/Hemiciclo).\n",
    "\n",
    "Usad `scrappy` para extraer la siguiente información:\n",
    "\n",
    "*Nombre*, *Territorio*, *Partido*, *URL Imagen*, en el formato de un diccionario, como por ejemplo:\n",
    "\n",
    "`{'Nombre': 'Callejas Cano, Juan Antonio ', 'Territorio': 'Diputado por Ciudad Real', 'Partido': 'G.P. Popular en el Congreso', 'url': '/wc/htdocs/web/img/diputados/peq/35_14.jpg'}`\n",
    "\n",
    "Para Ello: \n",
    "\n",
    "- Utilizad el tutorial de scrappy para encontrar un `xpath` que contenga la información requerida\n",
    "- Extraed la información requerida en forma de diccionario.\n",
    "\n",
    "**Nota**: si la ejecución del _crawler_ os devuelve un error `ReactorNotRestartable`, reiniciad el núcleo del Notebook (en el menú: `Kernel` - `Restart`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías.\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.http import TextResponse\n",
    "import logging\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Referencia cargar páginas en scrapy directamente](https://stackoverflow.com/questions/26177620/how-to-execute-scrapy-shell-url-with-notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primera alternativa para obtener la información mediante scrapeo a través del paquete http de la librería scrapy.\n",
    "# Obtenemos el HTML de la página web.\n",
    "res = requests.get('https://www.congreso.es/web/guest/busqueda-de-diputados?p_p_id=diputadomodule&p_p_lifecycle=0&p_p_state=normal&p_p_mode=view&_diputadomodule_mostrarFicha=true&codParlamentario=319&idLegislatura=XIV&false=false')\n",
    "\n",
    "# Cargamos el HTML con scrapy para poder extraer información.\n",
    "response = TextResponse(res.url, body = res.text, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_congress(response):\n",
    "    # Creamos el diccionario y vamos añadiendo la información clave-valor.\n",
    "    congress = {}\n",
    "    # Utilizamos la función `extract` para obtener el contenido del elemento que nos interesa y la función `strip` para\n",
    "    # eliminar los espacios en blanco antes y después del contenido elegido.\n",
    "    congress['Nombre'] = response.xpath('//div[@class=\"nombre-dip\"]/text()').extract()[0].strip()\n",
    "    congress['Territorio'] = response.xpath('//div[@class=\"cargo-dip\"]/text()').extract()[0].strip()\n",
    "    group = response.xpath('//div[@class=\"grupo-dip\"]/a/text()').extract()[0].strip()\n",
    "    # Aplicamos una regrex para eliminar el exceso de espacios en blanco entre palabras.\n",
    "    congress['Partido'] = re.sub(r\"\\s+\", \" \" , group)\n",
    "    congress['url'] = response.xpath('//div[@class=\"img-dip\"]/img/@src').extract()[0]\n",
    "    \n",
    "    return congress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Nombre': 'Iglesias Turrión, Pablo',\n",
       " 'Territorio': 'Diputado por Madrid',\n",
       " 'Partido': 'G.P. Confederal de Unidas Podemos-En Comú Podem-Galicia en Común ( GCUP-EC-GC )',\n",
       " 'url': '/docu/imgweb/diputados/319_14.jpg'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos la función.\n",
    "get_info_congress(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Referencia usar araña dentro de un notebook](https://www.mikulskibartosz.name/how-to-scrape-a-single-web-page-using-scrapy-in-jupyter-notebook/)   \n",
    "[Referencia guardar resultado en variable en vez de archivo](https://stackoverflow.com/questions/48573298/saving-the-output-of-spider-in-a-variable-rather-than-in-a-file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-11 14:34:03 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)\n",
      "2021-01-11 14:34:03 [scrapy.utils.log] INFO: Versions: lxml 4.6.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1i  8 Dec 2020), cryptography 3.1.1, Platform Windows-10-10.0.18362-SP0\n",
      "2021-01-11 14:34:03 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n",
      "2021-01-11 14:34:03 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 30}\n"
     ]
    }
   ],
   "source": [
    "# Segunda alternativa para obtener la información mediante scrapeo a través del paquete crawler de la librería scrapy.\n",
    "# Creamos una clase araña que define el método para recolectar información.\n",
    "class PoliticianData(scrapy.Spider):\n",
    "    name = \"PoliticianData\"\n",
    "    # Determinamos la url que queremos scrapear.\n",
    "    start_urls = [\n",
    "        'https://www.congreso.es/web/guest/busqueda-de-diputados?p_p_id=diputadomodule&p_p_lifecycle=0&p_p_state=normal&p_p_mode=view&_diputadomodule_mostrarFicha=true&codParlamentario=43&idLegislatura=XIV&false=false'\n",
    "    ]\n",
    "    # Configuramos el log_level para mostrar solo los warnings.\n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING\n",
    "    }\n",
    "    # Definimos el método para extraer la información deseada,   \n",
    "    def parse(self, response):\n",
    "        self.output[\"Nombre\"] = response.xpath('//div[@class=\"nombre-dip\"]/text()').extract()[0].strip()\n",
    "        self.output['Territorio'] = response.xpath('//div[@class=\"cargo-dip\"]/text()').extract()[0].strip()\n",
    "        group = response.xpath('//div[@class=\"grupo-dip\"]/a/text()').extract()[0].strip()\n",
    "        # Aplicamos una regrex para eliminar el exceso de espacios en blanco entre palabras.\n",
    "        self.output['Partido'] = re.sub(r\"\\s+\", \" \" , group)\n",
    "        self.output['url'] = response.xpath('//div[@class=\"img-dip\"]/img/@src').extract()[0]\n",
    "\n",
    "# Creamos un diccionario en el que guardaremos los datos.\n",
    "data_diputado = {}\n",
    "\n",
    "# Inicializamos el crawler.\n",
    "process = CrawlerProcess()\n",
    "# Indicamos al crawler la araña que tiene que ejecutar y pasamos por parámetro el objeto en el que guardaremos el resultado.\n",
    "process.crawl(PoliticianData, output=data_diputado)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Nombre': 'Abascal Conde, Santiago',\n",
       " 'Territorio': 'Diputado por Madrid',\n",
       " 'Partido': 'G.P. VOX ( GVOX )',\n",
       " 'url': '/docu/imgweb/diputados/43_14.jpg'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos el resultado del crawleo.\n",
    "data_diputado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio opcional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consultad la paǵina web de Open Notify, indicando la información sobre los humanos residentes fuera de la tierra (es decir, en el espacio). Dirección url en  [Open Notify](http://api.open-notify.org).\n",
    "\n",
    "Codificad una función que imprima por pantalla el número total de astronautas en el espacio, numero de naves tripuladas actualmente en órbita, así como el nombre de los astronautas que habitan para cada una de estas naves. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la función que extrae la información de los astronautas y las naves en el espacio.\n",
    "def get_space_info():\n",
    "    # Realizamos una petición GET a la API People in Space.\n",
    "    response = requests.get('http://api.open-notify.org/astros.json')\n",
    "    # Deserializamos el objeto json.\n",
    "    dict_response = json.loads(response.text)\n",
    "    \n",
    "    # Obtenemos el número de astronautas.\n",
    "    n_astronauts = dict_response[\"number\"]\n",
    "    # Guardamos las naves utilizando un list comprehension y un set para eliminar duplicados y quedarnos solo con las naves \n",
    "    # que no estén repetidas.\n",
    "    ships = set([person[\"craft\"] for person in dict_response[\"people\"]])\n",
    "    # Obtenemos el número de naves distintas.\n",
    "    n_ships = len(ships)\n",
    "    # Creamos un diccionario para almacenar las tripulaciones.\n",
    "    crews = {}\n",
    "    \n",
    "    # Iteramos sobre las naves para saber qué personas hay en cada nave y obtener el nombre.\n",
    "    for ship in ships:\n",
    "        # Asignamos a la key de la nave la lista de nombres que están en dicha nave.\n",
    "        crews[ship] = [person[\"name\"] for person in dict_response[\"people\"] if person[\"craft\"] == ship]\n",
    "    \n",
    "    # Mostramos por pantalla la información que nos interesa.\n",
    "    print(f\"El número de astronautas en el espacio es {n_astronauts}\")\n",
    "    print(f\"-----------------------------------------------------------------\")\n",
    "    print(f\"El número de naves en el espacio es {n_ships}\")\n",
    "    print(f\"-----------------------------------------------------------------\")\n",
    "    print(f\"Las diferentes tripulaciones son: \\n {crews}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de astronautas en el espacio es 7\n",
      "-----------------------------------------------------------------\n",
      "El número de naves en el espacio es 1\n",
      "-----------------------------------------------------------------\n",
      "Las diferentes tripulaciones son: \n",
      " {'ISS': ['Sergey Ryzhikov', 'Kate Rubins', 'Sergey Kud-Sverchkov', 'Mike Hopkins', 'Victor Glover', 'Shannon Walker', 'Soichi Noguchi']}\n"
     ]
    }
   ],
   "source": [
    "# Probamos la función.\n",
    "get_space_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
